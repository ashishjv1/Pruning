{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\ashis\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.utils.prune as prune\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "import test\n",
    "import train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "##Dataset - CIFAR10 Dataset for demonstration\n",
    "\n",
    "trn_batch_size = 64\n",
    "val_batch_size = 64\n",
    "\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "transforms.RandomCrop(32, padding = 4),\n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "valid_tfms = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "\n",
    "fullset = datasets.CIFAR10(root='./data10', train=True, download=True, transform=train_tfms)\n",
    "testset = datasets.CIFAR10(root='./data10', train=False, download=True, transform=valid_tfms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(fullset, batch_size=trn_batch_size,\n",
    "                                            shuffle=False, pin_memory=True, num_workers=1)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(testset, batch_size=val_batch_size,\n",
    "                                        shuffle=False, pin_memory=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model ResNet18 for Demonstration purpose\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = models.resnet50().to(device)\n",
    "model.load_state_dict(torch.load('resnet50.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 25.2740, Test Accuracy: 0.02%\n",
      "Inference time Before Pruning: 56.046891927719116s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Evaluate the model using the imported module\n",
    "start = time.time()\n",
    "test.evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=trainloader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")\n",
    "print(f\"Inference time Before Pruning: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned weights for conv1:\n",
      " tensor([[[[-0.0000, -0.0000,  0.0374,  ...,  0.0479, -0.0000,  0.0000],\n",
      "          [-0.0574,  0.0447,  0.0775,  ...,  0.0884,  0.0293, -0.0583],\n",
      "          [ 0.0684, -0.2704,  0.4035,  ..., -0.1649,  0.2187, -0.0729],\n",
      "          ...,\n",
      "          [-0.1087,  0.3815, -0.4549,  ...,  0.6837, -0.5786,  0.2246],\n",
      "          [ 0.0257, -0.1770,  0.6437,  ...,  0.5264, -0.0493, -0.0681],\n",
      "          [ 0.0453, -0.1307,  0.0000,  ..., -0.3575,  0.1898, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  ...,  0.0869, -0.0655,  0.0000],\n",
      "          [-0.0335,  0.0391,  0.0866,  ...,  0.1171,  0.0000, -0.0441],\n",
      "          [ 0.0553, -0.2642,  0.4269,  ..., -0.2372,  0.3202, -0.1183],\n",
      "          ...,\n",
      "          [-0.1266,  0.5317, -0.6581,  ...,  0.9423, -0.7809,  0.2364],\n",
      "          [-0.0262, -0.1331,  0.7207,  ...,  0.6755, -0.0447, -0.0769],\n",
      "          [ 0.0575, -0.1175,  0.0612,  ..., -0.4092,  0.2330, -0.0529]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0381,  ...,  0.0399, -0.0556,  0.0358],\n",
      "          [-0.0000,  0.0582, -0.0246,  ...,  0.0802, -0.0298,  0.0000],\n",
      "          [ 0.0407, -0.1299,  0.2606,  ..., -0.0000,  0.0972, -0.0580],\n",
      "          ...,\n",
      "          [-0.1086,  0.2438, -0.2091,  ...,  0.4110, -0.4527,  0.1749],\n",
      "          [ 0.0442, -0.2340,  0.4740,  ...,  0.3139, -0.0363, -0.0671],\n",
      "          [ 0.0449, -0.0547, -0.0608,  ..., -0.2446,  0.1775, -0.0354]]],\n",
      "\n",
      "\n",
      "        [[[-0.0273,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0384],\n",
      "          [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0350, -0.1576, -0.2743,  ..., -0.2491, -0.1268, -0.0355],\n",
      "          ...,\n",
      "          [ 0.1315,  0.4608,  0.6789,  ...,  0.6376,  0.3361,  0.1591],\n",
      "          [-0.1372, -0.4520, -0.7262,  ..., -0.5958, -0.2756, -0.0946],\n",
      "          [-0.0000,  0.0000,  0.0251,  ...,  0.0279, -0.0351, -0.0484]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0288,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0554, -0.2028, -0.3206,  ..., -0.2870, -0.1645, -0.0559],\n",
      "          ...,\n",
      "          [ 0.1956,  0.4778,  0.7296,  ...,  0.6977,  0.3721,  0.2185],\n",
      "          [-0.2004, -0.5606, -0.8459,  ..., -0.6916, -0.3424, -0.1460],\n",
      "          [-0.0233,  0.0000,  0.0233,  ...,  0.0264, -0.0000, -0.0400]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0777, -0.1040,  ..., -0.0840, -0.0294,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0377,  0.1621,  0.3435,  ...,  0.2527,  0.1082,  0.0629],\n",
      "          [-0.0558, -0.2289, -0.3512,  ..., -0.2813, -0.1095, -0.0000],\n",
      "          [-0.0000,  0.0481,  0.0858,  ...,  0.0426, -0.0000, -0.0578]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0250],\n",
      "          [-0.0000,  0.0000, -0.0000,  ..., -0.0247, -0.0247, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0401,  ...,  0.0000, -0.0418, -0.0575],\n",
      "          ...,\n",
      "          [-0.0262, -0.0333, -0.0000,  ...,  0.2156,  0.0760, -0.0650],\n",
      "          [-0.0000, -0.0000, -0.0322,  ...,  0.0541,  0.0000, -0.0435],\n",
      "          [ 0.0000, -0.0239, -0.0375,  ..., -0.0553, -0.0659, -0.0794]],\n",
      "\n",
      "         [[-0.0432, -0.0000, -0.0412,  ..., -0.0407, -0.0461, -0.0000],\n",
      "          [-0.0241,  0.0000, -0.0000,  ...,  0.0460,  0.0000,  0.0313],\n",
      "          [-0.0513, -0.0000,  0.0639,  ...,  0.3253,  0.1408,  0.0478],\n",
      "          ...,\n",
      "          [-0.0546,  0.0405,  0.2874,  ...,  0.8314,  0.4449,  0.1161],\n",
      "          [-0.0631, -0.0258,  0.1309,  ...,  0.4669,  0.1835,  0.0294],\n",
      "          [-0.0398,  0.0000,  0.0241,  ...,  0.1343,  0.0000,  0.0391]],\n",
      "\n",
      "         [[ 0.0314,  0.0297,  0.0504,  ...,  0.0397,  0.0616,  0.0438],\n",
      "          [ 0.0000, -0.0000,  0.0287,  ..., -0.0000,  0.0263, -0.0000],\n",
      "          [ 0.0676,  0.0276, -0.0000,  ..., -0.3360, -0.1286,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0758, -0.0000, -0.3135,  ..., -1.0637, -0.5296, -0.0633],\n",
      "          [ 0.0683,  0.0477, -0.1078,  ..., -0.5463, -0.2020,  0.0000],\n",
      "          [ 0.0502, -0.0000,  0.0240,  ..., -0.0923,  0.0332,  0.0414]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0452,  0.0000,  0.0249,  ...,  0.0848,  0.0295,  0.0323],\n",
      "          [ 0.0434,  0.2028,  0.3869,  ...,  0.6145,  0.5183,  0.3327],\n",
      "          [-0.0000,  0.1429,  0.3698,  ...,  0.6856,  0.5649,  0.3274],\n",
      "          ...,\n",
      "          [-0.0000, -0.0917, -0.1776,  ..., -0.3644, -0.3172, -0.2040],\n",
      "          [ 0.0261, -0.1765, -0.3570,  ..., -0.6848, -0.5945, -0.3445],\n",
      "          [-0.0549, -0.2324, -0.3942,  ..., -0.6454, -0.5494, -0.3468]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0639,  ..., -0.0936, -0.0709, -0.0599],\n",
      "          [-0.0000, -0.0403, -0.0754,  ..., -0.0623, -0.0523, -0.0399],\n",
      "          ...,\n",
      "          [ 0.0308,  0.0000,  0.0000,  ...,  0.0251,  0.0000,  0.0402],\n",
      "          [ 0.0000,  0.0376,  0.0621,  ...,  0.0614,  0.0637,  0.0634],\n",
      "          [-0.0000,  0.0489,  0.0461,  ...,  0.0869,  0.0918,  0.0773]],\n",
      "\n",
      "         [[ 0.0351, -0.0000, -0.0000,  ..., -0.0575, -0.0461, -0.0356],\n",
      "          [-0.0471, -0.1781, -0.2983,  ..., -0.5342, -0.4419, -0.2632],\n",
      "          [ 0.0410, -0.1068, -0.3324,  ..., -0.5936, -0.4816, -0.2730],\n",
      "          ...,\n",
      "          [-0.0000,  0.0698,  0.1743,  ...,  0.3436,  0.2815,  0.1743],\n",
      "          [-0.0291,  0.1484,  0.3231,  ...,  0.6256,  0.5024,  0.2827],\n",
      "          [ 0.0285,  0.1781,  0.3489,  ...,  0.5422,  0.4702,  0.2778]]],\n",
      "\n",
      "\n",
      "        [[[-0.0602, -0.0000,  0.1619,  ..., -0.0000,  0.0268, -0.0000],\n",
      "          [ 0.0000,  0.1622,  0.2333,  ..., -0.0739,  0.0645, -0.0481],\n",
      "          [ 0.1464,  0.2767, -0.1572,  ..., -0.1787,  0.2712,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0837, -0.2008,  ...,  1.9357,  0.4305, -0.4435],\n",
      "          [ 0.0341,  0.1082,  0.1742,  ...,  0.5624, -0.7475, -0.5704],\n",
      "          [-0.0269, -0.0000, -0.0000,  ..., -0.2697, -0.5889,  0.0000]],\n",
      "\n",
      "         [[ 0.0462, -0.0300, -0.0242,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0472, -0.1117, -0.0345,  ...,  0.0000, -0.0286,  0.0000],\n",
      "          [-0.0372, -0.0373,  0.2391,  ...,  0.0626, -0.0000,  0.0281],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000,  0.0858,  ..., -0.6338, -0.1813,  0.0435],\n",
      "          [-0.0000, -0.0579,  0.0000,  ..., -0.1844,  0.1752,  0.1926],\n",
      "          [ 0.0000,  0.0000,  0.0553,  ..., -0.0000,  0.1855,  0.0736]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.1232,  ...,  0.0380, -0.0000, -0.0000],\n",
      "          [ 0.0383, -0.0335, -0.1979,  ...,  0.0647, -0.0362,  0.0407],\n",
      "          [-0.0989, -0.2329, -0.0883,  ...,  0.1006, -0.2396, -0.0491],\n",
      "          ...,\n",
      "          [ 0.0325,  0.0794,  0.1280,  ..., -1.2784, -0.2331,  0.3741],\n",
      "          [-0.0000, -0.0503, -0.1848,  ..., -0.3485,  0.5510,  0.3818],\n",
      "          [ 0.0000,  0.0000, -0.0503,  ...,  0.2558,  0.3976, -0.0937]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000,  ..., -0.0291, -0.0000,  0.0000],\n",
      "          [ 0.0322,  0.0000,  0.0000,  ...,  0.0776, -0.0856, -0.0659],\n",
      "          [-0.0000,  0.0000, -0.1354,  ...,  0.1949,  0.2667,  0.0367],\n",
      "          ...,\n",
      "          [ 0.0000, -0.0370,  0.0280,  ...,  0.3024, -0.0934,  0.0354],\n",
      "          [-0.0000, -0.0000, -0.1556,  ...,  0.0398,  0.0696, -0.0496],\n",
      "          [ 0.0000,  0.0250,  0.0430,  ..., -0.0482, -0.0343, -0.0000]],\n",
      "\n",
      "         [[-0.0279,  0.0000,  0.0994,  ..., -0.0406, -0.0616, -0.0000],\n",
      "          [-0.0702, -0.1217, -0.0358,  ...,  0.4647,  0.1291, -0.0372],\n",
      "          [-0.0426, -0.1112, -0.5793,  ...,  0.1572,  0.6100,  0.3834],\n",
      "          ...,\n",
      "          [ 0.0726,  0.0760,  0.3769,  ...,  0.4894, -0.4814, -0.3381],\n",
      "          [-0.0369, -0.0677, -0.2015,  ...,  0.3922,  0.3263, -0.1054],\n",
      "          [-0.0296, -0.0000, -0.0257,  ..., -0.0884,  0.0874,  0.0614]],\n",
      "\n",
      "         [[-0.0000,  0.0537,  0.0911,  ..., -0.0857, -0.0624,  0.0000],\n",
      "          [-0.0732, -0.1218, -0.0000,  ...,  0.3286, -0.0409, -0.1133],\n",
      "          [-0.0368, -0.0599, -0.4304,  ...,  0.1972,  0.5112,  0.1908],\n",
      "          ...,\n",
      "          [ 0.0619,  0.0000,  0.1958,  ...,  0.4034, -0.3988, -0.2834],\n",
      "          [-0.0000, -0.0000, -0.1705,  ...,  0.3055,  0.3259, -0.0573],\n",
      "          [-0.0000,  0.0000, -0.0000,  ..., -0.0799,  0.0809,  0.0885]]]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Mask applied to conv1 weights:\n",
      " tensor([[[[0., 0., 1.,  ..., 1., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 0.,  ..., 1., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "          [0., 0., 1.,  ..., 0., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 0., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 0., 0.,  ..., 1., 0., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 0., 1., 0.],\n",
      "          [1., 1., 0.,  ..., 1., 1., 0.],\n",
      "          ...,\n",
      "          [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 0., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 0., 0.,  ..., 1., 0., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.,  ..., 0., 1., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 0.,  ..., 1., 1., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "          ...,\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 0., 1., 1.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 1., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "          [1., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Single layer Pruning\n",
    "\n",
    "prune.l1_unstructured(model.conv1, name=\"weight\", amount=0.25)\n",
    "\n",
    "# Check the pruned weights and the mask\n",
    "print(\"Pruned weights for conv1:\\n\", model.conv1.weight)\n",
    "print(\"Mask applied to conv1 weights:\\n\", model.conv1.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning Multiple layers\n",
    "layers_to_prune = [\"conv1\", \"layer1.0.conv1\"]\n",
    "\n",
    "for layer_name in layers_to_prune:\n",
    "   \n",
    "    modules = layer_name.split('.')\n",
    "    layer = model\n",
    "    for module in modules:\n",
    "        if module.isdigit():\n",
    "            layer = layer[int(module)] \n",
    "        else:\n",
    "            layer = getattr(layer, module)\n",
    "\n",
    "    prune.l1_unstructured(layer, name=\"weight\", amount=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 25.5385, Test Accuracy: 0.01%\n",
      "Inference time After Pruning: 61.08184218406677s\n"
     ]
    }
   ],
   "source": [
    "# Calculate Inference time after pruning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "test.evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=trainloader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")\n",
    "print(f\"Inference time After Pruning: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2977, Accuracy: 63.84%\n",
      "Epoch [2/10], Loss: 0.6320, Accuracy: 79.05%\n"
     ]
    }
   ],
   "source": [
    "# Finetune for 10 Epochs\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "optimizer_name = 'Adam'\n",
    "scheduler_name = 'StepLR'\n",
    "lr = 0.001\n",
    "step_size = 10\n",
    "gamma = 0.1\n",
    "model_path = 'pmodel.pth'\n",
    "\n",
    "# Train and save the model using the imported module\n",
    "saved_model_path = train.train_and_save_model(\n",
    "    model=model,\n",
    "    train_loader=trainloader,\n",
    "    num_epochs=num_epochs,\n",
    "    optimizer_name=optimizer_name,\n",
    "    scheduler_name=scheduler_name,\n",
    "    lr=lr,\n",
    "    step_size=step_size,\n",
    "    gamma=gamma,\n",
    "    model_path=model_path,\n",
    "    mask_dict=None\n",
    ")\n",
    "\n",
    "print(f\"Trained model saved to {saved_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
